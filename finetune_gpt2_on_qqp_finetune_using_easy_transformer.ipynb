{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173f2ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from easy_transformer.utils import get_corner, gelu_new, tokenize_and_concatenate\n",
    "from easy_transformer import EasyTransformer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4427307",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_gpt2 = EasyTransformer.from_pretrained(\"gpt2-small\", fold_ln=False, center_unembed=False, center_writing_weights=False)\n",
    "reference_gpt2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799f6e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params = sum(p.numel() for p in reference_gpt2.parameters())\n",
    "print(\"Number of parameters in GPT-2 Small model:\", num_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab9706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qqp = load_dataset(\"glue\",'qqp' split=\"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baa1d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_qqp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29beb722",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "for each in train_qqp:\n",
    "    values.append(each['is_duplicate'])\n",
    "set(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7da158a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_qqp['questions']), len(train_qqp['is_duplicate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a78d620",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qqp_text, validation_qqp_text, train_qqp_label, validation_qqp_label  = train_test_split(train_qqp['questions'], train_qqp['is_duplicate'], test_size=0.1, random_state=42)\n",
    "train_qqp_text = train_qqp_text[:3000]\n",
    "validation_qqp_text = validation_qqp_text[:500]\n",
    "train_qqp_label = train_qqp_label[:3000]\n",
    "validation_qqp_label = validation_qqp_label[:500]\n",
    "\n",
    "print(\"Train set size:\", len(train_qqp_text))\n",
    "print(\"Validation set size:\", len(validation_qqp_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f4d34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = 0\n",
    "ct = 0\n",
    "for each in train_qqp_label:\n",
    "    if each== False:\n",
    "        cf += 1\n",
    "    if each == True:\n",
    "        ct += 1\n",
    "print(cf, ct)\n",
    "\n",
    "cf = 0\n",
    "ct = 0\n",
    "for each in validation_qqp_label:\n",
    "    if each == False:\n",
    "        cf += 1\n",
    "    if each == True:\n",
    "        ct += 1\n",
    "print(cf, ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d03597",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qqp_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf37ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, questions, labels, model, max_length = 1024, token_to_add = 50256):\n",
    "        self.questions = questions\n",
    "        self.labels = labels\n",
    "        self.max_length = max_length\n",
    "        self.token_to_add = token_to_add\n",
    "        self.model = model\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sentence1 = self.questions[idx]['text'][0]\n",
    "        sentence1_tokens = self.model.to_tokens(sentence1, prepend_bos = False)\n",
    "        sentence2 = self.questions[idx]['text'][1]\n",
    "        sentence2_tokens = self.model.to_tokens(sentence2, prepend_bos = False)\n",
    "        \n",
    "        token_to_add = torch.tensor([50256], dtype=torch.long)\n",
    "        token_to_add = token_to_add.unsqueeze(0) \n",
    "        sentence1_tokens = torch.cat((sentence1_tokens, token_to_add), dim=1)\n",
    "        concatenated_tokens = torch.cat((sentence1_tokens, sentence2_tokens), dim=1)\n",
    "        \n",
    "        if self.labels[idx] == True:\n",
    "            labels = torch.tensor(1)\n",
    "        else:\n",
    "            labels = torch.tensor(0)\n",
    "        \n",
    "        remaining_length = self.max_length - concatenated_tokens.size(1)\n",
    "        while remaining_length > 0:\n",
    "            concatenated_tokens = torch.cat((concatenated_tokens, torch.tensor([[self.token_to_add]])), dim=1)\n",
    "            remaining_length -= 1\n",
    "\n",
    "        \n",
    "        return concatenated_tokens, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e820938c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(train_qqp_text, train_qqp_label, reference_gpt2, max_length = 1024, token_to_add = 50256)\n",
    "data_loader_train = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "len(data_loader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4da2247",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(validation_qqp_text, validation_qqp_label, reference_gpt2, max_length = 1024, token_to_add = 50256)\n",
    "data_loader_valid = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "len(data_loader_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcc7ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tokens, labels in data_loader_train:\n",
    "    print(\"Tokens:\", tokens.shape)\n",
    "    print(\"Labels:\", labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcd8b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_gpt2.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3b4929",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CustomGPT2ForSequenceClassification(EasyTransformer):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.unembed = None\n",
    "        self.classification_head = torch.nn.Linear(config.d_model * config.n_ctx, num_labels)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, input_ids):\n",
    "       \n",
    "        embed = self.embed(tokens=input_ids)\n",
    "        embed = embed.squeeze(1)\n",
    "        #print('embed',embed.shape)\n",
    "        pos_embed = self.pos_embed(input_ids)\n",
    "        #print('pos_embed',pos_embed.shape)\n",
    "        residual = embed + pos_embed\n",
    "        #print('residual', residual.shape)\n",
    "        for block in self.blocks:\n",
    "            normalized_resid_pre = block.ln1(residual)\n",
    "            #print('normalized_resid_pre', normalized_resid_pre.shape)\n",
    "            attn_out = block.attn(normalized_resid_pre)\n",
    "            #print('attn_out', attn_out.shape)\n",
    "            resid_mid = residual + attn_out\n",
    "            #print('resid_mid', resid_mid.shape)\n",
    "\n",
    "            normalized_resid_mid = block.ln2(resid_mid)\n",
    "            #print('normalized_resid_mid', normalized_resid_mid.shape)\n",
    "            mlp_out = block.mlp(normalized_resid_mid)\n",
    "            #print('mlp_out', mlp_out.shape)\n",
    "            resid_post = resid_mid + mlp_out\n",
    "            #print('resid_post', resid_post.shape)\n",
    "        normalized_resid_final = self.ln_final(resid_post)\n",
    "        #print('normalized_resid_final', normalized_resid_final.shape)\n",
    "        normalized_resid_final = normalized_resid_final.view(normalized_resid_final.shape[0], -1)\n",
    "        #print('normalized_resid_final', normalized_resid_final.shape)\n",
    "        logits = self.classification_head(normalized_resid_final)\n",
    "        return logits      \n",
    "\n",
    "# Example usage:\n",
    "config = reference_gpt2.cfg\n",
    "num_labels = 2  \n",
    "model = CustomGPT2ForSequenceClassification(config)\n",
    "model.load_state_dict(reference_gpt2.state_dict(), strict=False)\n",
    "device = torch.device(\"mps\")\n",
    "model.to(device)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9137945e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "model.float() \n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    # Wrap the dataloader with tqdm to add the progress bar\n",
    "    for input_ids, labels in tqdm(data_loader_train, desc=f'Epoch {epoch + 1}/{num_epochs}'):\n",
    "        input_ids = input_ids.to(device).long() \n",
    "        labels = labels.to(device).long() \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids)\n",
    "        \n",
    "        loss = loss_fn(logits, labels)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_samples += input_ids.size(0)\n",
    "        total_correct += (logits.argmax(dim=-1) == labels).sum().item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Calculate metrics\n",
    "    accuracy = total_correct / total_samples\n",
    "    average_loss = total_loss / len(data_loader_train)\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {average_loss}, Accuracy: {accuracy}\")\n",
    "    torch.save(model.state_dict(), '../trained_models/easy_transformer_gpt2small_qqp_try.pth')\n",
    "    \n",
    "model.eval()\n",
    "total_loss = 0\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "for input_ids, labels in tqdm(data_loader_valid, desc=f'Epoch {epoch + 1}/{num_epochs}'):\n",
    "    input_ids = input_ids.to(device).long() \n",
    "    labels = labels.to(device).long() \n",
    "    logits = model(input_ids)        \n",
    "    loss = loss_fn(logits, labels)\n",
    "    total_loss += loss.item()\n",
    "    total_samples += input_ids.size(0)\n",
    "    total_correct += (logits.argmax(dim=-1) == labels).sum().item()\n",
    "accuracy = total_correct / total_samples\n",
    "average_loss = total_loss / len(data_loader_valid)\n",
    "print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {average_loss}, Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f385db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a957cdf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dd9628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6403c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16838ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18aa14b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24cee7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a9362f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc94ba89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
