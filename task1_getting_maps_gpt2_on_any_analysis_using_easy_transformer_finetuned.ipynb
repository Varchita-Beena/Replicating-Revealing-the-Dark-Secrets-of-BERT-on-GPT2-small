{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173f2ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from easy_transformer import EasyTransformer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4427307",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_gpt2 = EasyTransformer.from_pretrained(\"gpt2-small\", fold_ln=False, center_unembed=False, center_writing_weights=False)\n",
    "reference_gpt2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b312e0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CustomGPT2ForSequenceClassification(EasyTransformer):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.unembed = None\n",
    "        self.classification_head1 = torch.nn.Linear(config.d_model * config.n_ctx, num_labels)        \n",
    "        \n",
    "    def forward(self, input_ids):\n",
    "       \n",
    "        embed = self.embed(tokens=input_ids)\n",
    "        embed = embed.squeeze(1)\n",
    "        #print('embed',embed.shape)\n",
    "        pos_embed = self.pos_embed(input_ids)\n",
    "        #print('pos_embed',pos_embed.shape)\n",
    "        residual = embed + pos_embed\n",
    "        #print('residual', residual.shape)\n",
    "        for block in self.blocks:\n",
    "            normalized_resid_pre = block.ln1(residual)\n",
    "            #print('normalized_resid_pre', normalized_resid_pre.shape)\n",
    "            attn_out = block.attn(normalized_resid_pre)\n",
    "            #print('attn_out', attn_out.shape)\n",
    "            resid_mid = residual + attn_out\n",
    "            #print('resid_mid', resid_mid.shape)\n",
    "\n",
    "            normalized_resid_mid = block.ln2(resid_mid)\n",
    "            #print('normalized_resid_mid', normalized_resid_mid.shape)\n",
    "            mlp_out = block.mlp(normalized_resid_mid)\n",
    "            #print('mlp_out', mlp_out.shape)\n",
    "            resid_post = resid_mid + mlp_out\n",
    "            #print('resid_post', resid_post.shape)\n",
    "        normalized_resid_final = self.ln_final(resid_post)\n",
    "        #print('normalized_resid_final', normalized_resid_final.shape)\n",
    "        normalized_resid_final = normalized_resid_final.view(normalized_resid_final.shape[0], -1)\n",
    "        #print('normalized_resid_final', normalized_resid_final.shape)\n",
    "        logits = self.classification_head1(normalized_resid_final)\n",
    "        return logits\n",
    "        \n",
    "config = reference_gpt2.cfg\n",
    "num_labels = 2\n",
    "model = CustomGPT2ForSequenceClassification(config)\n",
    "model_path = '../trained_models/easy_transformer_gpt2small_qqp_try.pth' \n",
    "state_dict = torch.load(model_path)\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "device = torch.device(\"mps\")\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e27a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb58cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Number of parameters in GPT-2 Small model:\", num_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac57a01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = load_dataset('glue', 'qqp', split='train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0272099",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset[0], len(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71aca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_integer = 5310\n",
    "validation_dataset[random_integer]['question1']#, validation_dataset[random_integer]['sentence2'], validation_dataset[random_integer]['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f38ba83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(datapoint, max_length = 1024, token_to_add = 50256):\n",
    "    sep_place = [0]\n",
    "    sentence1 = datapoint['question1']\n",
    "    sentence1_tokens = reference_gpt2.to_tokens(sentence1, prepend_bos = False)\n",
    "    \n",
    "    sep_2 = sentence1_tokens.size(1)\n",
    "    sep_place.append(sep_2+1)\n",
    "    sentence2 = datapoint['question2']\n",
    "    sentence2_tokens = reference_gpt2.to_tokens(sentence2, prepend_bos = False)\n",
    "    \n",
    "    token_to_add = torch.tensor([50264], dtype=torch.long)\n",
    "    token_to_add = token_to_add.unsqueeze(0) \n",
    "    sentence1_tokens = torch.cat((sentence1_tokens, token_to_add), dim=1)\n",
    "    concatenated_tokens = torch.cat((sentence1_tokens, sentence2_tokens), dim=1)\n",
    "    \n",
    "    labels = torch.tensor(datapoint['label'])\n",
    "    real_length = concatenated_tokens.size(1)\n",
    "    remaining_length = max_length - concatenated_tokens.size(1)\n",
    "    while remaining_length > 0:\n",
    "        concatenated_tokens = torch.cat((concatenated_tokens, torch.tensor([[token_to_add]])), dim=1)\n",
    "        remaining_length -= 1\n",
    "    return concatenated_tokens, labels, real_length, sep_place\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1db081",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens, label, length, seperators = tokenize(validation_dataset[random_integer])\n",
    "tokens, label, length, seperators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676c28f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_hooks(module):\n",
    "    def hook(module, input, output):\n",
    "        print(\"Output shape:\", output.shape)  \n",
    "    # Register the hook to the module\n",
    "    module.register_forward_hook(hook)\n",
    "\n",
    "for module in model.modules():\n",
    "    print(module)\n",
    "    register_hooks(module)\n",
    "    break\n",
    "\n",
    "outputs = model(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d0fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_scores_list = []\n",
    "def register_attention_hooks(module):\n",
    "    if isinstance(module, EasyTransformer):\n",
    "        for i, block in enumerate(module.blocks):\n",
    "            attention_module = block.attn.hook_attn\n",
    "            def hook(module, input, output):\n",
    "                attention_scores = output[0]\n",
    "                attention_scores_list.append(attention_scores)\n",
    "            attention_module.register_forward_hook(hook)\n",
    "\n",
    "register_attention_hooks(model)\n",
    "outputs = model(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a512b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_scores_list[0].shape, len(attention_scores_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed142a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '../gpt2_small/attention_arrays/qqp_5310_try/'\n",
    "for attention in range(len(attention_scores_list)):\n",
    "    for head in range(attention_scores_list[attention].shape[0]):\n",
    "        print(attention, head)\n",
    "        file_name = folder + 'attn_' + str(attention) + '_' + str(head) + '.npy'\n",
    "        np.save(file_name, attention_scores_list[attention][head, :, :].cpu().detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a79cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a881ffbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9b7294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
